# Documentation de Configuration de Kubernetes sur Ubuntu 24.04 ğŸš€

## ğŸ—ï¸ Architecture actuelle du cluster

| Noeud | vCPU | RAM (Go) | OS |
|-------|------|----------|----|
| Master | 2 | 4 | Ubuntu 24.04 |
| Worker | 2 | 4 | Ubuntu 24.04 |

## ğŸ”„ Mise Ã  Jour des Paquets du Serveur

```bash
sudo apt-get update && sudo apt-get -y upgrade
```

## âŒ DÃ©sactiver l'Ã‰change sur les NÅ“uds de Cluster

1. ğŸ”’ Pour **dÃ©sactiver** de faÃ§on **temporaire** :

    ```bash
    sudo swapoff -a
    ```
2. ğŸ”’ Pour **dÃ©sactiver** de faÃ§on **permanente** :
   
   ```bash
   sudo sed -i '/swap/s/^/#/' /etc/fstab
   ```

## ğŸŒ Activer le Transfert d'Adresse IP du Noyau

1. ğŸŒ Pour activer le **Transfert** d'Adresse IP du Noyau :
   
   ```bash
   echo "net.ipv4.ip_forward=1" | sudo tee -a  /etc/sysctl.conf
   ```
2. ğŸ”„ **Appliquer** les modifications :
   ```bash
   sudo sysctl -p
   ```

## ğŸ›  Charger les Modules de Noyau NÃ©cessaires

1. ğŸ“ **VÃ©rifiez** si ces modules sont activÃ©s/chargÃ©s :
   
   ```bash
   sudo lsmod | grep -E "overlay|br_netfilter"
   ```
2. â• **Ajouter** les configurations suivantes :
   
   ```bash
   sudo tee -a /etc/sysctl.conf << 'EOL'
   net.bridge.bridge-nf-call-iptables = 1
   net.bridge.bridge-nf-call-ip6tables = 1
   EOL
   ```
3. âš™ï¸ **Appliquer** les modifications :

    ```bash
   sudo sysctl -p
   ```

## ğŸ“¦ Installer Container Runtime

```bash
sudo apt install apt-transport-https ca-certificates curl gnupg-agent software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/docker.gpg
echo "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -sc) stable" | sudo tee /etc/apt/sources.list.d/docker-ce.list
sudo apt update
sudo apt install -y containerd.io
```

## âš™ï¸ Configurer le Pilote Cgroup pour ContainerD

1. ğŸ—‚ï¸ **CrÃ©er** le dossier de configuration si nÃ©cessaire :
   
    ```bash
    [ -d /etc/containerd ] || sudo mkdir /etc/containerd
    ```
2. ğŸ“„ **GÃ©nÃ©rer** le fichier de configuration par dÃ©faut :

    ```bash
    containerd config default | sudo tee /etc/containerd/config.toml
    ```
3. ğŸ”§ **Changer** la valeur de `SystemdCgroup` de **false** Ã  **true** :
   
    ```bash
    sudo sed -i '/SystemdCgroup/s/false/true/' /etc/containerd/config.toml
    ```
4. ğŸ“¦ **Mettre Ã  jour** la version de pause :
   
    ```bash
    sudo sed -i '/pause:3.8/s/3.8/3.9/' /etc/containerd/config.toml
    ```
5. ğŸ” **VÃ©rifier** la version de pause :

    ```bash
    grep sandbox_image /etc/containerd/config.toml
    ```
6. ğŸš€ **DÃ©marrer** et **activer** containerd pour quâ€™il sâ€™exÃ©cute au dÃ©marrage :
   
    ```bash
    sudo systemctl enable --now containerd
    ```

    > ğŸš« Attention ! ğŸš«
    Il est possible pour les Ã©tapes suivantes que le lancement du cluster **Ã©choue**, car parfois, certains services alternatifs Ã  kubernetes sont **prÃ©installÃ©s** lors de la configuration de l'**OS** ; Afin d'y remÃ©dier, **supprimer en amont** le sevice `microk8s` s'il existe : `sudo snap remove microk8s`
7. ğŸ“Š **RedÃ©marrer** et **vÃ©rifier** l'Ã©tat de containerd :
   
    ```bash
    systemctl restart containerd && systemctl status containerd
    ```

## ğŸ›¡ï¸ Installer Kubernetes sur Ubuntu 24.04

1. ğŸ”‘ **Installer** la ClÃ© de Signature GPG :
   
    ```bash
    sudo apt install gnupg2 -y
    VER=1.30
    curl -fsSL https://pkgs.k8s.io/core:/stable:/v${VER}/deb/Release.key | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/k8s.gpg
    ```
2. â• **Ajouter** le RÃ©fÃ©rentiel Kubernetes :
   
    ```bash
    echo "deb https://pkgs.k8s.io/core:/stable:/v${VER}/deb/ /" | sudo tee /etc/apt/sources.list.d/kurbenetes.list
    ```
3. ğŸ› ï¸ **Installer** les Composants Kubernetes :

    ```bash
    sudo apt update
    sudo apt install kubelet kubeadm kubectl -y
    ```
4. ğŸ“¦ **Marquer** les Packages Kubernetes :
   
    ```bash
    sudo apt-mark hold kubeadm kubelet kubectl
    ```
## ğŸŒ€ Initialiser le Cluster Kubernetes :

```bash
sudo kubeadm init --apiserver-advertise-address=172.30.0.43 --pod-network-cidr=10.68.11.0/24
```
1. ğŸ‘¤ Passer en Mode **Utilisateur Normal** :

    ```bash
    su - lakuzass
    ```
2. ğŸ“ **CrÃ©er** le RÃ©pertoire de Cluster Kubernetes :

    ```bash
    mkdir -p $HOME/.kube
    ```
3. ğŸ“„ **Copier** le Fichier de Configuration de lâ€™Administrateur :

    ```bash
    sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
    sudo chown $(id -u):$(id -g) $HOME/.kube/config
    ```
4. ğŸ” VÃ©rifier l'Ã‰tat du Cluster :

    ```bash
    kubectl get nodes
    kubectl cluster-info
    ```

## ğŸ“¡ Installer l'Addon RÃ©seau Pod sur le NÅ“ud MaÃ®tre

1. â• **DÃ©ployer** le rÃ©seau Pod :
   
    ```bash
    kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
    ```
2. ğŸ“¥ **Installer** `Calico Pod network addon Operator` :
   
    ```bash
    CNI_VER=3.29.0
    kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v${CNI_VER}/manifests/tigera-operator.yaml
    wget https://raw.githubusercontent.com/projectcalico/calico/v${CNI_VER}/manifests/custom-resources.yaml
    ```
3. ğŸ“‚ **Afficher** le fichier :

    ```bash
    cat custom-resources.yaml
    ```
4. ğŸ”„ **Mettre Ã  jour** le sous-rÃ©seau :

    ```bash
    sed -i 's/192.168/10.100/' custom-resources.yaml
    ```
5. ğŸ“¦ **Appliquer** les modifications :

    ```bash
    kubectl create -f custom-resources.yaml
    ```

## ğŸ“‹ Obtenir des Pods en Cours dâ€™ExÃ©cution

1. ğŸ“ **Lister** les Pods dans les espaces de noms :

    ```bash
    kubectl get pods --all-namespaces
    ```
2. ğŸ” **RÃ©pertorier** les Pods dans des espaces de noms spÃ©cifiques :

    ```bash
    kubectl get pods -n calico-system
    ```

## ğŸ”“ Ouvrir les Ports du Cluster sur le Pare-feu

1. ğŸ›¡ï¸<u>Ports du Plan de ContrÃ´le :</u>
   
    | Protocole | Direction | Plage de ports | But | UtilisÃ© par |
    |-----------|-----------|----------------|-----|-------------|
    | TCP       | Entrants  | 6443           | Serveur dâ€™API Kubernetes | Tout |
    | TCP       | Entrants  | 2379-2380      | API du client du serveur etcd | kube-apiserver, etcd |
    | TCP       | Entrants  | 10250          | Kubelet API | Soi, Plan de contrÃ´le |
    | TCP       | Entrants  | 10259          | kube-scheduler | MÃªme |
    | TCP       | Entrants  | 10257          | kube-controller-manager | MÃªme |
2. ğŸ”“ **Ouvrir** les ports :

    ```bash
    for i in 6443 2379:2380 10250:10252; do sudo ufw allow from any to any port $i proto tcp; done
    ```
3. ğŸ”’ **Restreindre** lâ€™accÃ¨s Ã  lâ€™API Ã  partir de rÃ©seaux/IPS spÃ©cifiques :
    - âš™ï¸<u>Ports des NÅ“uds de Travail :</u>
        | Protocole | Direction | Plage de ports | But | UtilisÃ© par |
        |-----------|-----------|----------------|-----|-------------|
        | TCP       | Entrants  | 10250          | Kubelet API | Soi, Plan de contrÃ´le |
        | TCP       | Entrants  | 30000-32767    | NodePort Services | Tout |
4. ğŸ”“ **Ouvrir** le port API Kubelet :

    ```bash
    ufw allow from any to any port 10250 proto tcp comment "Open Kubelet API port"
    ```

## â• Ajouter des NÅ“uds de Travail au Cluster

1. ğŸ” **VÃ©rifier** que le runtime du conteneur est en cours dâ€™exÃ©cution :

    ```bash
    systemctl status containerd
    ```
2. ğŸ“‹ **Imprimer** la commande join sur le **nÅ“ud maÃ®tre** :

    ```bash
    kubeadm token create --print-join-command
    ```

3. ğŸ“¥ **ExÃ©cuter** la commande reÃ§ue sur le **nÅ“ud worker** :

    ```bash
    kubeadm join 172.30.0.43:6443 --token uvtz2h.azomw8u4o2a55u57 --discovery-token-ca-cert-hash sha256:b5a3b73437440231910e77e9d76fd3e80b813d820ef39212b6e19c304608ab69
    ```
4. ğŸ” **VÃ©rifier** la prÃ©sence du nÅ“ud :
   
    ```bash
    kubectl get nodes
    ```
5. ğŸ› ï¸ **Mettre Ã  jour** le rÃ´le :

    ```bash
    kubectl label node worker node-role.kubernetes.io/worker=true
    ```

## ğŸ“Š Obtenir des Informations sur le Cluster
```bash
kubectl cluster-info
kubectl api-resources
```

---
# âœ¨ Installation du Dashboard Kubernetes âœ¨

> âœ… **ExÃ©cuter toutes les commandes en tant qu'utilisateur normal** via `su - eureka`

## ğŸ“„ Installation du dashboard Kubernetes sur le noeud maÃ®tre du cluster

> âš™ï¸ **Remplacer la valeur de la variable** `VER` par la [version actuelle](https://github.com/kubernetes/dashboard/releases)

```bash
VER=2.7.0 && kubectl apply -f \
https://raw.githubusercontent.com/kubernetes/dashboard/v${VER}/aio/deploy/recommended.yaml
```

## ğŸ” VÃ©rification de lâ€™installation du dashboard

1. ğŸ”¢ **Afficher les namespaces** :

    ```bash
    kubectl get namespaces
    ```
    â†’ **Retour attendu** :
    ```bash
    NAME                   STATUS   AGE
    calico-apiserver       Active   17h
    calico-system          Active   17h
    default                Active   17h
    kube-node-lease        Active   17h
    kube-public            Active   17h
    kube-system            Active   17h
    kubernetes-dashboard   Active   17h
    tigera-operator        Active   17h
    ```

2. ğŸ“ **Lister les pods dans l'espace `kubernetes-dashboard`** :

    ```bash
    kubectl get pods -n kubernetes-dashboard -o wide
    ```
    â†’ **Retour attendu** :
    ```bash
    NAME                                         READY   STATUS    RESTARTS   AGE   IP             NODE       NOMINATED NODE   READINESS GATES
    dashboard-metrics-scraper-795895d745-42xr5   1/1     Running   0          17h   10.68.11.194   yval0160   <none>           <none>
    kubernetes-dashboard-56cf4b97c5-s2vlp        1/1     Running   0          17h   10.68.11.193   yval0160   <none>           <none>
    ```

3. â„¹ï¸ **Obtenir plus de dÃ©tails sur un pod** :
    ```bash
    kubectl describe pod kubernetes-dashboard-56cf4b97c5-s2vlp -n kubernetes-dashboard
    ```

## ğŸ  Exposer le dashboard Kubernetes pour un accÃ¨s externe

1. ğŸ› ï¸ **Reconfigurer le service** pour un accÃ¨s via NodePort :

    ```bash
    kubectl edit service kubernetes-dashboard -n kubernetes-dashboard
    ```
    > **Sous la section** `spec`, ajouter :
    > - `nodePort: 30001`
    > - Modifier le type de `ClusterIP` en `NodePort`

    â†’ **Exemple** :
    ```bash
    spec:
        clusterIP: 10.97.96.182
        clusterIPs:
        - 10.97.96.182
        externalTrafficPolicy: Cluster
        internalTrafficPolicy: Cluster
        ipFamilies:
        - IPv4
        ipFamilyPolicy: SingleStack
        ports:
        - nodePort: 30001
          port: 443
          protocol: TCP
          targetPort: 8443
        selector:
            k8s-app: kubernetes-dashboard
        sessionAffinity: None
        type: NodePort
    ```

2. â“ **VÃ©rifier les ports Node actuellement utilisÃ©s** :

    ```bash
    kubectl get services --all-namespaces -o jsonpath='{range .items[*]}{.spec.ports[*].nodePort}{"\n"}{end}'
    ```

3. ğŸ“Š **VÃ©rifier le service et la prise en compte du port** :

    ```bash
    kubectl get services -n kubernetes-dashboard
    ```
    â†’ **Retour attendu** :
    ```bash
    NAME                        TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE
    dashboard-metrics-scraper   ClusterIP   10.111.14.67   <none>        8000/TCP        17h
    kubernetes-dashboard        NodePort    10.97.96.182   <none>        443:30001/TCP   17h
    ```

## ğŸ›¡ï¸ CrÃ©er un compte administrateur pour le dashboard

1. ğŸ““ **CrÃ©ation du fichier de configuration de l'utilisateur** :

    ```bash
    vim kubernetes-dashboard-admin-user.yml
    ```
    â†’ **Contenu Ã  insÃ©rer** :
    ```yaml
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: admin-user
      namespace: kubernetes-dashboard
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: admin-user
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: cluster-admin
    subjects:
    - kind: ServiceAccount
      name: admin-user
      namespace: kubernetes-dashboard
    ```

2. âœï¸ **CrÃ©er le compte administrateur** :

    ```bash
    kubectl apply -f kubernetes-dashboard-admin-user.yml
    ```
    > â„¹ï¸ **VÃ©rification** : utiliser `kubectl get serviceaccounts -n kubernetes-dashboard` pour confirmer.

3. ğŸ” **GÃ©nÃ©rer un jeton d'accÃ¨s** :

    ```bash
    kubectl create token admin-user -n kubernetes-dashboard
    ```
    > â— **Conserver ce jeton** pour la connexion web.

## ğŸ”— AccÃ¨s au dashboard Kubernetes

âœ‰ï¸ **AccÃ©der au dashboard Kubernetes** Ã  partir dâ€™un navigateur via lâ€™adresse IP de n'importe quel nÅ“ud du cluster sur le port `30001/tcp` en HTTPS.

- **Exemples dâ€™accÃ¨s** :
    - [Dashboard noeud maÃ®tre](https://172.30.0.43:30001)
    - [Dashboard noeud worker](https://172.30.0.45:30001)

---